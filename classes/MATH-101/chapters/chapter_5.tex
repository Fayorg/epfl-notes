\chapter{Function of Real Numbers}

\section{Functions}
\begin{definition}[Real Function]
    A function $f : E \to F$, where $E$ and $F$ are subsets of $\mathbb{R}$, is a rule that assigns to each element $x \in E$ a unique element $f(x) \in F$. The set $E = \text{D}(f)$ is called the domain of the function, and the set $F$ is called the codomain.
\end{definition}

\begin{definition}[Graph of a Function]
    The graph of a function $f : E \to F$ is the set of points in the Cartesian plane defined by:
    \[
        G(f) = \{(x, f(x)) \mid x \in E\}
    \]
\end{definition}
\begin{eg}
    The graph of the function $f(x) = x^2$ is the set of points:
    \[
        G(f) = \{(x, x^2) \mid x \in \mathbb{R}\}
    \]
    Thus:
    \begin{center}
        \begin{tikzpicture}[scale=1.5]
            \draw[->] (-2, 0) -- (2, 0) node[right] {$x$};
            \draw[->] (0, -0.5) -- (0, 2.75) node[above] {$y$};
            \draw[thick, primary, domain=-1.5:1.5, samples=50] plot (\x, {(\x)^2});
        \end{tikzpicture}
    \end{center}
\end{eg}

\subsection{Properties of Functions}
% \begin{definition}[Growing Function]
%     A function $f : E \to \mathbb{R}$ is said to be increasing ($f(x) \uparrow$) on an interval $I \subseteq E$ if for all $x_1, x_2 \in I$ such that $x_1 < x_2$, we have:
%     \[
%         f(x_1) \leq f(x_2)
%     \]
%     If the inequality is strict, i.e., $f(x_1) < f(x_2)$, then $f$ is said to be strictly increasing on $I$.
% \end{definition}

% \begin{definition}[Decreasing Function]
%     A function $f : E \to \mathbb{R}$ is said to be decreasing ($f(x) \downarrow$) on an interval $I \subseteq E$ if for all $x_1, x_2 \in I$ such that $x_1 < x_2$, we have:
%     \[
%         f(x_1) \geq f(x_2)
%     \]
%     If the inequality is strict, i.e., $f(x_1) > f(x_2)$, then $f$ is said to be strictly decreasing on $I$.
% \end{definition}

\begin{definition}[Increasing and Decreasing Functions]
    A function $f : E \to \mathbb{R}$ is said to be increasing on an interval $I \subseteq E$ if for all $x_1, x_2 \in I$ such that $x_1 < x_2$, we have:
    \[
        f(x_1) \leq f(x_2)
    \]
    If the inequality is strict, i.e., $f(x_1) < f(x_2)$, then $f$ is said to be strictly increasing on $I$. \\
    Similarly, a function $f : E \to \mathbb{R}$ is said to be decreasing on an interval $I \subseteq E$ if for all $x_1, x_2 \in I$ such that $x_1 < x_2$, we have:
    \[
        f(x_1) \geq f(x_2)
    \]
    If the inequality is strict, i.e., $f(x_1) > f(x_2)$, then $f$ is said to be strictly decreasing on $I$.
\end{definition}
Note that a function (strictly) increasing or (strictly) decreasing on an interval $I$ is also called (strictly) monotonic on $I$.

\begin{definition}[Even and Odd Functions]
    A function $f : E \to \mathbb{R}$ is said to be even if for all $x \in E$, we have:
    \[
        f(-x) = f(x)
    \]
    A function $f : E \to \mathbb{R}$ is said to be odd if for all $x \in E$, we have:
    \[
        f(-x) = -f(x)
    \]
    % TODO: Add graphs for examples of even and odd functions
\end{definition}
\begin{eg}
    The function $f(x) = x^2$ is even since for all $x \in \mathbb{R}$, we have:
    \[
        f(-x) = (-x)^2 = x^2 = f(x)
    \]
    Graphically, even functions are symmetric with respect to the y-axis.
    \begin{center}
        \begin{tikzpicture}[scale=1.5]
            \draw[->] (-2, 0) -- (2, 0) node[right] {$x$};
            \draw[->, secondary, thick] (0, -0.5) -- (0, 2.75) node[above] {$y$};
            \draw[thick, primary, domain=-1.5:1.5, samples=50] plot (\x, {(\x)^2});
        \end{tikzpicture}
    \end{center}
    The function $g(x) = x^3$ is odd since for all $x \in \mathbb{R}$, we have:
    \[
        g(-x) = (-x)^3 = -x^3 = -g(x)
    \]
    Graphically, odd functions are symmetric with respect to the origin.
    \begin{center}
        \begin{tikzpicture}[scale=1.5]
            \draw[->] (-2, 0) -- (2, 0) node[right] {$x$};
            \draw[->] (0, -2) -- (0, 2) node[above] {$y$};
            \draw[thick, primary, domain=-1.2:1.2, samples=50] plot (\x, {(\x)^3});
            \draw[secondary, thick, domain=-1.7:1.7, samples=2] plot (\x, {\x});
        \end{tikzpicture}
    \end{center}
\end{eg}

\begin{definition}[Periodic Function]
    A function $f : E \to \mathbb{R}$ is said to be periodic with period $T > 0$ if for all $x \in E$ such that $x \pm T \in E$, we have:
    \[
        f(x \pm T) = f(x)
    \]
\end{definition}
\begin{eg}
    The function $f(x) = \sin(x)^2$ is periodic with period $2\pi$, since we have:
    \[
        \sin(x)^2 = \left(\frac{e^{ix} - e^{-ix}}{2i}\right)^2 = \frac{e^{2ix} - 2 + e^{-2ix}}{-4} = \frac{1}{2} - \frac{1}{2}\cos(2x)
    \]
    Since $\cos(x)$ is periodic with period $2\pi$, we have that $\sin(x)^2$ is also periodic with a period of $\pi$ (or $\sin(x)^2$ is $\pi$-periodic).
    Graphically, we have:
    \begin{center}
        \begin{tikzpicture}[scale=1.5]
            \draw[->] (-2, 0) -- (2, 0) node[right] {$x$};
            \draw[->] (0, -0.5) -- (0, 1.5) node[above] {$y$};
            \draw[thick, primary, domain=-1.5:1.5, samples=150] plot (\x, {sin(deg(\x * 4))^2});

            \draw[<->, secondary, thick] (-0.8, -0.1) -- (0, -0.1) node[midway, below] {$\pi$};
            \draw[<->, secondary, thick] (0.8, -0.1) -- (0, -0.1) node[midway, below] {$\pi$};
        \end{tikzpicture}
    \end{center}
\end{eg}
\begin{eg}
    Some functions are periodic but it's impossible to find the smallest period. For example, the function:
    \[
        f(x) = \begin{cases}
            0 & \text{if } x \in \mathbb{Q} \\
            1 & \text{if } x \notin \mathbb{Q}
        \end{cases}
    \]
    In other words, for any rational number $P$:
    \[
        \begin{cases}
            \text{rational} + P = \text{rational} \\
            \text{irrational} + P = \text{irrational}
        \end{cases}
    \]
    Thus, $f(x + P) = f(x)$ for any rational number $P$, making $f$ a periodic function without a smallest period.
\end{eg}

\subsection{Boundedness and Extrema of Functions}
\begin{definition}[Bounded Function]
    A function $f : E \to \mathbb{R}$ is said to be bounded above on a set $A \subseteq E$ if the set $f(A) \subset \mathbb{R}$ is bounded above, i.e., there exists a real number $M$ such that for all $x \in A$, we have:
    \[
        f(x) \leq M
    \]
    Similarly, $f$ is said to be bounded below on $A$ if the set $f(A) \subset \mathbb{R}$ is bounded below, i.e., there exists a real number $m$ such that for all $x \in A$, we have:
    \[
        f(x) \geq m
    \]
    If $f$ is both bounded above and bounded below on $A$, then it is said to be bounded on $A$.
\end{definition}

\begin{definition}[Supremum and Infimum]
    A function $f : E \to \mathbb{R}$ has a supremum (least upper bound) on a set $A \subseteq E$, denoted by $\sup_{x \in A} f(x)$, if the set $f(A) \subset \mathbb{R}$ has a supremum. This means that:
    \[
        \sup_{x \in A} f(x) = \sup \{f(x), x \in A\}
    \]
    Similarly, $f$ has an infimum (greatest lower bound) on $A$, denoted by $\inf_{x \in A} f(x)$, if the set $f(A) \subset \mathbb{R}$ has an infimum. This means that:
    \[
        \inf_{x \in A} f(x) = \inf \{f(x), x \in A\}
    \]
\end{definition}
\begin{eg}
    Let $f: (0,1) \to \mathbb{R}$ defined by $f(x) = x^2 + 3$ be bounded on $A = (0,1)$. Then:
    \[
        \sup_{x \in A} f(x) = \sup \{x^2 + 3, x \in A\} = 4 \notin f(A)
    \]
    Similarly:
    \[
        \inf_{x \in A} f(x) = \inf \{x^2 + 3, x \in A\} = 3 \notin f(A)
    \]
\end{eg}

\begin{definition}[Local Maximum and Minimum]
    A function $f: E \to \mathbb{R}$ has a local maximum at a point $x_0 \in E$ if there exists $\delta > 0$ such that for all $x \in E$ with $|x - x_0| < \delta$, we have:
    \[
        f(x) \leq f(x_0)
    \]
    Similarly, $f$ has a local minimum at a point $x_0 \in E$ if there exists $\delta > 0$ such that for all $x \in E$ with $|x - x_0| < \delta$, we have:
    \[
        f(x) \geq f(x_0)
    \]
\end{definition}

\begin{definition}[Global Maximum and Minimum]
    A function $f: E \to \mathbb{R}$ has a global maximum at a point $x_0 \in E$ if for all $x \in E$, we have:
    \[
        f(x) \leq f(x_0)
    \]
    Similarly, $f$ has a global minimum at a point $x_0 \in E$ if for all $x \in E$, we have:
    \[
        f(x) \geq f(x_0)
    \]
\end{definition}
\begin{eg}
    Let's show the difference between local and global extrema graphically:
    \begin{center}
        \begin{tikzpicture}[scale=1.3]
            \draw[->] (-0.5, 0) -- (3.5, 0) node[right] {$x$};
            \draw[->] (0, -0.5) -- (0, 2.5) node[above] {$y$};
            \draw[thick, primary, domain=0:2.5, samples=100] plot (\x, {-(\x - 1)^2 + 2});

            \filldraw[secondary, thick] (1, 2) circle (1.5pt) node[above right] {Global Max};
            \filldraw[secondary, thick] (0, 1) circle (1.5pt) node[above left] {Local Min};
            \filldraw[secondary, thick] (2.49, -0.2) circle (1.5pt) node[below right] {Global Min};
        \end{tikzpicture}
    \end{center}
\end{eg}
If the $\max_{x \in E} f(x)$ (or $\min_{x \in E} f(x)$) exists, then $f$ is bounded above (or below) on $E$ and $\sup_{x \in E} f(x) = \max_{x \in E} f(x)$ (or $\inf_{x \in E} f(x) = \min_{x \in E} f(x)$). \\
A bounded function on $E$ does not necessarily reach its bounds, i.e., the maximum or minimum may not exist.
\begin{eg}
    Let $f: [0, 1) \to \mathbb{R}$ defined by $f(x) = x^2 + 3$. We clearly see that $f$ is bounded but:
    \[
        \max_{x \in [0, 1)} f(x) = 4 \notin f([0, 1))
    \]
    i.e. $f$ does not reach its upper bound and:
    \[
        \min_{x \in [0, 1)} f(x) = 3 \in f([0, 1))
    \]
    i.e. $f$ reaches its lower bound at $x = 0$:
    \[
        f(0) = 3 = \min_{x \in [0, 1)} f = \inf_{x \in [0, 1)} f
    \]
\end{eg}

\subsection{Types of Functions}
\begin{definition}[Surjectivity]
    A function $f : E \to F$ is said to be surjective (onto) if for every $y \in F$, there exists at least one $x \in E$ such that $f(x) = y$.
\end{definition}
\begin{definition}[Injectivity]
    A function $f : E \to F$ is said to be injective (one-to-one) if for every $x_1, x_2 \in E$, whenever $f(x_1) = f(x_2)$, it follows that $x_1 = x_2$ (i.e. there exists at most one $x \in E$ for each $y \in F$ such that $f(x) = y$).
\end{definition}
If $f: E \to F$ is not injective, it can be made injective by restricting its domain $E$ and if $f$ is not surjective, it can be made surjective by adjusting its codomain $F$.

\begin{definition}[Bijectivity]
    A function $f : E \to F$ is said to be bijective if it is both injective and surjective. In this case, for every $y \in F$, there exists a unique $x \in E$ such that $f(x) = y$.
\end{definition}

\begin{definition}[Inverse Function]
    Let $f : E \to F$ be a bijective function. The inverse function of $f$, denoted by $f^{-1} : F \to E$, is defined by:
    \[
        f^{-1}(y) = x \quad \text{where} \quad f(x) = y
    \]
    for every $y \in F$.
\end{definition}
By convention, for the trigonometric functions, the inverse sine, cosine, and tangent functions are defined on restricted domains to ensure bijectivity:
\begin{itemize}[itemsep=1pt,label=$\circ$]
    \item $\sin : \left[-\frac{\pi}{2}, \frac{\pi}{2}\right] \to [-1, 1]$, reciprocally $\arcsin : [-1, 1] \to \left[-\frac{\pi}{2}, \frac{\pi}{2}\right]$
    \item $\cos : [0, \pi] \to [-1, 1]$, reciprocally $\arccos : [-1, 1] \to [0, \pi]$
    \item $\tan : \left(-\frac{\pi}{2}, \frac{\pi}{2}\right) \to \mathbb{R}$, reciprocally $\arctan : \mathbb{R} \to \left(-\frac{\pi}{2}, \frac{\pi}{2}\right)$
    \item $\cot : (0, \pi) \to \mathbb{R}$, reciprocally $\text{arccot} : \mathbb{R} \to (0, \pi)$
\end{itemize}
\begin{eg}
    Graphically, the inverse function $f^{-1}$ of a bijective function $f$ can be obtained by reflecting the graph of $f$ across the line $y = x$:
    \begin{center}
        \begin{tikzpicture}[scale=1]
            \draw[->] (-0.5, 0) -- (3.5, 0) node[right] {$x$};
            \draw[->] (0, -0.5) -- (0, 3.5) node[above] {$y$};
            \draw[thick, primary, domain=0:2.5, samples=100] plot (\x, {0.5 * (\x)^2}) node[above] {$f$};
            \draw[thick, secondary, domain=0:3, samples=100] plot (\x, {sqrt(2 * \x)}) node[right] {$f^{-1}$};
            \draw[dashed] (0, 0) -- (3.5, 3.5) node[above right] {$y = x$};
        \end{tikzpicture}
    \end{center}
\end{eg}
\begin{eg}
    Let $f = \frac{1}{\cos(x)^2 + 1}$ defined on $\mathbb{R}$. Let's find the biggest interval containing $x= 1$ where $f$ is bijective. \\
    We have:
    \[
        \frac{1}{y + 1} \quad \text{is injective} \quad \forall y \in [0, +\infty)
    \]
    and 
    \[
        \cos(x)^2 \quad \text{is injective} \quad  \forall x \in [0, \frac{\pi}{2}]
    \]
    Since $1 \in [0, \frac{\pi}{2}]$, thus $f$ is injective on the interval $\left[0, \frac{\pi}{2}\right]$. We also have:
    \[
        f(x) = \frac{1}{\cos(x)^2 + 1} \quad x \in \left[0, \frac{\pi}{2}\right]
    \]
    is increasing since $\cos(x)^2$ is decreasing on $\left[0, \frac{\pi}{2}\right]$ and thus:
    \[        
        \inf_{x \in \left[0, \frac{\pi}{2}\right]} f(x) = f\left(\frac{\pi}{2}\right) = \frac{1}{2} \quad \text{and} \quad \sup_{x \in \left[0, \frac{\pi}{2}\right]} f(x) = f(0) = 1
    \]
    Therefore, $f : \left[0, \frac{\pi}{2}\right] \to \left[\frac{1}{2}, 1\right]$ is bijective and its inverse function is given by:
    \[
        f^{-1}(y) = \arccos\left(\sqrt{\frac{1}{y} - 1}\right) \quad y \in \left[\frac{1}{2}, 1\right]
    \]
\end{eg}

\subsection{Composite Functions}
\begin{definition}[Composite Function]
    Let $f : E \to F$ and $g : F \to G$ be two functions. The composite function of $f$ and $g$, denoted by $g \circ f : E \to G$, is defined by:
    \[
        (g \circ f)(x) = g(f(x))
    \]
    for every $x \in E$.
\end{definition}
\begin{eg}
    Let $f : \mathbb{R} \to \mathbb{R}$ be defined by $f(x) = 2x + 3$ and let $g : \mathbb{R} \to \mathbb{R}$ be defined by $g(x) = x^2$. Then, the composite function $g \circ f : \mathbb{R} \to \mathbb{R}$ is given by:
    \[
        (g \circ f)(x) = g(f(x)) = g(2x + 3) = (2x + 3)^2 = 4x^2 + 12x + 9
    \]
    Note that the order of composition matters, as $f \circ g$ would yield a different result:
    \[
        (f \circ g)(x) = f(g(x)) = f(x^2) = 2x^2 + 3
    \]
\end{eg}
\begin{eg}
    Let $f: E \to F$ be a bijective function with inverse $f^{-1} : F \to E$. Then, the composite functions $f \circ f^{-1} : F \to F$ and $f^{-1} \circ f : E \to E$ are given by:
    \[
        (f \circ f^{-1})(y) = f(f^{-1}(y)) = y \quad \forall y \in F
    \]
    and
    \[
        (f^{-1} \circ f)(x) = f^{-1}(f(x)) = x \quad \forall x \in E
    \]
    Thus, composing a function with its inverse yields the identity function on the respective domains.
\end{eg}

\section{Limits of Functions}
\begin{definition}[Neighborhood]
    A function $f: E \to F$ is defined on a neighborhood of a point $x_0 \in E$ if there exists $\delta > 0$ such that:
    \[
        \left\{x \in E : 0 < |x - x_0| < \delta\right\} \subseteq E
    \]
\end{definition}
Remark that the function does not need to be defined at $x_0$ itself, only in its vicinity.

\begin{eg}
    Let $f = \frac{\sin (x)}{x}$ is defined on a neighborhood of $x_0 = 0$ but not at $x_0 = 0$ itself since $f(0)$ is undefined.
\end{eg}

\begin{definition}[Limit of a Function at a Point]
    Let $f: E \to F$ be a function defined on a neighborhood of a point $x_0 \in E$. It is said that the limit of $f(x)$ as $x$ approaches $x_0$ is equal to $L \in F$, denoted by:
    \[
        \lim_{x \to x_0} f(x) = L
    \]
    if for every $\epsilon > 0$, there exists a $\delta > 0$ such that for all $x \in E$ with $0 < |x - x_0| < \delta$, we have:
    \[
        |f(x) - L| < \epsilon
    \]
    \begin{center}
        \begin{tikzpicture}
            \draw[->] (-0.5, 0) -- (3.5, 0) node[right] {$x$};
            \draw[->] (0, -0.5) -- (0, 3.5) node[above] {$y$};
            \draw[thick, primary, domain=0:3, samples=100] plot (\x, {sqrt(2 * \x)}) node[right] {$f$};

            \draw[dashed] (2, 2) -- (2, 0) node[below] {$x_0$};
            \draw[dashed] (2.8, 2.36) -- (2.8, 0) node[below] {$x_0 + \delta$};
            \draw[dashed] (1.2, 1.54) -- (1.2, 0) node[below] {$x_0 - \delta$};
            \draw[<->, secondary, thick] (1.2, 0.5) -- (2.8, 0.5) node[midway, below left] {$\delta$};

            \draw[dashed] (2, 2) -- (0, 2) node[left] {$L$};
            \draw[dashed] (1.2, 1.54) -- (0, 1.54) node[left] {$L - \epsilon$};
            \draw[dashed] (2.8, 2.36) -- (0, 2.36) node[left] {$L + \epsilon$};
            \draw[<->, secondary, thick] (0.5, 1.54) -- (0.5, 2.36) node[midway, below left] {$\epsilon$};
        \end{tikzpicture}
    \end{center}
\end{definition}

\begin{eg}
    Let $f(x) = 3x - 1$ and $x_0 = 1$. Then:
    \[
        \lim_{x \to 1} f(x) = \lim_{x \to 1} (3x - 1) = 2
    \]
    To show this using the $\epsilon$-$\delta$ definition, let $\epsilon > 0$. We need to find $\delta > 0$ such that for all $x$ with $0 < |x - 1| < \delta$, we have:
    \[
        |f(x) - 2| < \epsilon
    \]
    We have:
    \[
        |f(x) - 2| = |3x - 1 - 2| = |3x - 3| = 3|x - 1|
    \]
    Thus, we want:
    \[
        3|x - 1| < \epsilon \quad \implies \quad |x - 1| < \frac{\epsilon}{3}
    \]
    Therefore, we can choose $\delta = \frac{\epsilon}{3}$. Hence, for all $x$ with $0 < |x - 1| < \delta$, we have:
    \[
        |f(x) - 2| < \epsilon
    \]
    This confirms that:
    \[
        \lim_{x \to 1} f(x) = 2
    \]
\end{eg}

\begin{eg}
    Let $f(x) = \sqrt{x} = \sqrt{x_0}, \forall x_0 > 0$. Then:
    \[
        \lim_{x \to x_0} f(x) = \lim_{x \to x_0} \sqrt{x} = \sqrt{x_0}
    \]
    To show this using the $\epsilon$-$\delta$ definition, let $\epsilon > 0$. We need to find $\delta > 0$ such that for all $x$ with $0 < |x - x_0| < \delta$, we have:
    \[
        |\sqrt{x} - \sqrt{x_0}| < \epsilon
    \]
    We have:
    \[
        |\sqrt{x} - \sqrt{x_0}| = \frac{|\sqrt{x} - \sqrt{x_0}| \cdot |\sqrt{x} + \sqrt{x_0}|}{|\sqrt{x} + \sqrt{x_0}|} = \frac{|x - x_0|}{|\sqrt{x} + \sqrt{x_0}|}
    \]
    To ensure that $|\sqrt{x} - \sqrt{x_0}| < \epsilon$, we need:
    \[
        \frac{|x - x_0|}{|\sqrt{x} + \sqrt{x_0}|} < \epsilon \quad \implies \quad |x - x_0| < \epsilon |\sqrt{x} + \sqrt{x_0}|
    \]
    Since we are considering $x$ in a neighborhood of $x_0$, we can assume that $x$ is close to $x_0$. Thus, we can find a lower bound for $|\sqrt{x} + \sqrt{x_0}|$. For instance, if we restrict $x$ to be in the interval $\left[x_0 - 1, x_0 + 1\right]$ (assuming $x_0 > 1$ for simplicity), we have:
    \[
        |\sqrt{x} + \sqrt{x_0}| \geq \sqrt{x_0} \quad \text{for all } x \in \left[x_0 - 1, x_0 + 1\right]
    \]
    Therefore, we can choose $\delta = \epsilon \sqrt{x_0}$. Hence, for all $x$ with $0 < |x - x_0| < \delta$, we have:
    \[
        |\sqrt{x} - \sqrt{x_0}| < \epsilon
    \]
    This confirms that:
    \[
        \lim_{x \to x_0} f(x) = \sqrt{x_0}
    \]
\end{eg}

\subsection{Caracterization of Limits by Sequences}
\begin{theorem}[Caracterization of Limits by Sequences]
    Let $f: E \to F$ be a function defined on a neighborhood of a point $x_0 \in E$. Then, the limit of $f(x)$ as $x$ approaches $x_0$ is equal to $L \in F$, i.e.:
    \[
        \lim_{x \to x_0} f(x) = L
    \]
    if and only if for every sequence $(x_n)$ in $E$ such that $\lim_{n \to +\infty} x_n = x_0$ and $x_n \neq x_0$ for all $n$, we have:
    \[
        \lim_{n \to +\infty} f(x_n) = L
    \]
\end{theorem}
\begin{proof}
    \textbf{($\Rightarrow$)} Assume that $\lim_{x \to x_0} f(x) = L$. Let $(x_n)$ be a sequence in $E$ such that $\lim_{n \to +\infty} x_n = x_0$ and $x_n \neq x_0$ for all $n$. For every $\epsilon > 0$, there exists $\delta > 0$ such that for all $x \in E$ with $0 < |x - x_0| < \delta$, we have:
    \[
        |f(x) - L| < \epsilon
    \]
    Since $\lim_{n \to +\infty} x_n = x_0$, there exists $N \in \mathbb{N}$ such that for all $n \geq N$, we have:
    \[
        |x_n - x_0| < \delta
    \]
    Therefore, for all $n \geq N$, we have:
    \[
        |f(x_n) - L| < \epsilon
    \]
    This shows that $\lim_{n \to +\infty} f(x_n) = L$. \\
    \textbf{($\Leftarrow$)} By contraposition, assume that $\lim_{x \to x_0} f(x) \neq L$. Then, there exists $\epsilon_0 > 0$ such that for every $\delta > 0$, there exists $x \in E$ with $0 < |x - x_0| < \delta$ such that:
    \[
        |f(x) - L| \geq \epsilon_0
    \]
    For each $n \in \mathbb{N}$, let $\delta = \frac{1}{n}$. Then, there exists $x_n \in E$ with $0 < |x_n - x_0| < \frac{1}{n}$ such that:
    \[
        |f(x_n) - L| \geq \epsilon_0
    \]
    This defines a sequence $(x_n)$ in $E$ such that $\lim_{n \to +\infty} x_n = x_0$ and $x_n \neq x_0$ for all $n$. However, we have:
    \[
        |f(x_n) - L| \geq \epsilon_0
    \]
    for all $n$, which implies that $\lim_{n \to +\infty} f(x_n) \neq L$. This completes the proof.
\end{proof}
Remark that the property needs to be true for every sequence converging to $x_0$ and not just for some particular sequences.
\begin{eg}
    Let $f$ be defined by:
    \[
        f(x) = \begin{cases}
            1 & x = \frac{1}{n}, n \in \mathbb{N}^* \\
            0 & \text{otherwise}
        \end{cases}
    \]
    We clearly see that $\lim_{x \to 0} f(x)$ does not exist but for the sequence $x_n = \frac{1}{n}$, we have:
    \[
        \lim_{n \to +\infty} f(x_n) = 1
    \]
    Showing the importance of the "for every sequence" condition in the theorem.
\end{eg}
Let $f : E \to F$ defined on a neighborhood of $x_0$. Let's suppose that for all sequences $(x_n)$ in $E$ such that $\lim_{n \to +\infty} x_n = x_0$ and $x_n \neq x_0$ for all $n$, we have:
\[
    (f(x_n)) \text{ is convergent} \implies \lim_{x \to x_0} f(x) \text{ exists.}
\]
\begin{proof}
    Let's prove this by contradiction. Assume that $\lim_{x \to x_0} f(x)$ does not exist. Then, there exist two sequences $(x_n)$ and $(y_n)$ in $E$ such that $\lim_{n \to +\infty} x_n = x_0$, $\lim_{n \to +\infty} y_n = x_0$, and:
    \[
        \lim_{n \to +\infty} f(x_n) = L_1 \quad \text{and} \quad \lim_{n \to +\infty} f(y_n) = L_2
    \]
    with $L_1 \neq L_2$. Now, we can construct a new sequence $(z_n)$ by interleaving the terms of $(x_n)$ and $(y_n)$:
    \[
        z_{2n} = x_n \quad \text{and} \quad z_{2n+1} = y_n
    \]
    for all $n \in \mathbb{N}$. This new sequence $(z_n)$ also converges to $x_0$ since both $(x_n)$ and $(y_n)$ converge to $x_0$. However, the sequence $(f(z_n))$ does not converge because:
    \[
        \lim_{n \to +\infty} f(z_{2n}) = L_1 \quad \text{and} \quad \lim_{n \to +\infty} f(z_{2n+1}) = L_2
    \]
    with $L_1 \neq L_2$. This contradicts our assumption that for all sequences converging to $x_0$, the sequence $(f(x_n))$ is convergent. Therefore, our initial assumption that $\lim_{x \to x_0} f(x)$ does not exist must be false. Hence, we conclude that $\lim_{x \to x_0} f(x)$ exists.
\end{proof}

\begin{eg}
    Let $f(x) = x^p, p \in \mathbb{N}^*$. Then, we have:
    \[
        \lim_{x \to x_0} f(x) = \lim_{x \to x_0} x^p = x_0^p
    \]
    To show this using the caracterization by sequences, let $(x_n)$ be an arbitrary sequence such that $\lim_{n \to +\infty} x_n = x_0$ and $x_n \neq x_0$ for all $n$. Additionally, let $a_n = x_n - x_0$ for all $n \in \mathbb{N}$ such that $\lim_{n \to +\infty} a_n = 0$. We have:
    \[
        f(x_n) = (x_0 + a_n)^p = \sum_{k=0}^{p} \binom{p}{k} x_0^{p-k} a_n^k
    \]
    Since $\lim_{n \to +\infty} a_n = 0$, we have:
    \[
        \lim_{n \to +\infty} f(x_n) = \sum_{k=0}^{p} \binom{p}{k} x_0^{p-k} \cdot 0^k = x_0^p
    \]
    Therefore, by the caracterization of limits by sequences, we conclude that:
    \[
        \lim_{x \to x_0} f(x) = x_0^p
    \]
\end{eg}

\begin{definition}[Uniqueness of Limits]
    Let $f: E \to F$ be a function defined on a neighborhood of a point $x_0 \in E$. If the limit of $f(x)$ as $x$ approaches $x_0$ exists, then it is unique. In other words, if:
    \[
        \lim_{x \to x_0} f(x) = L_1 \quad \text{and} \quad \lim_{x \to x_0} f(x) = L_2
    \]
    then $L_1 = L_2$.
\end{definition}
\begin{proof}
    Assume that $\lim_{x \to x_0} f(x) = L_1$ and $\lim_{x \to x_0} f(x) = L_2$. Let $(x_n)$ be an arbitrary sequence such that $\lim_{n \to +\infty} x_n = x_0$ and $x_n \neq x_0$ for all $n$. By the caracterization of limits by sequences, we have:
    \[
        \lim_{n \to +\infty} f(x_n) = L_1 \quad \text{and} \quad \lim_{n \to +\infty} f(x_n) = L_2
    \]
    Since the limit of a sequence is unique, we conclude that $L_1 = L_2$. Therefore, the limit of $f(x)$ as $x$ approaches $x_0$ is unique.
\end{proof}

\begin{theorem}[Cauchy Criterion for Limits of Functions]
    Let $f: E \to F$ be a function defined on a neighborhood of a point $x_0 \in E$. Then, the limit of $f(x)$ as $x$ approaches $x_0$ exists if and only if for every $\epsilon > 0$, there exists a $\delta > 0$ such that for all $x, y \in E$ with $0 < |x - x_0| < \delta$ and $0 < |y - x_0| < \delta$, we have:
    \[
        |f(x) - f(y)| < \epsilon
    \]
\end{theorem}

\subsection{Operations on Limits}
\begin{definition}
    Let $f: E \to F$ and $g: E \to F$ be two functions defined on a neighborhood of a point $x_0 \in E$ such that the limits $\lim_{x \to x_0} f(x) = l_1$ and $\lim_{x \to x_0} g(x) = l_2$, then we can define the following operations on their limits:
    \begin{itemize}[itemsep=1pt,label=$\circ$]
        \item Sum: $\lim_{x \to x_0} (\alpha f(x) + \beta g(x)) = \alpha l_1 + \beta l_2$
        \item Product: $\lim_{x \to x_0} (f(x) \cdot g(x)) = l_1 \cdot l_2$
        \item Quotient: If $l_2 \neq 0$, then $\lim_{x \to x_0} \left(\frac{f(x)}{g(x)}\right) = \frac{l_1}{l_2}$
    \end{itemize}
\end{definition}
For all polynomial function $P$ and rational function $R = \frac{P_1}{P_2}$ (with $P_2 \neq 0$) defined for all $x_0 \in \mathbb{R}$ except the roots of $P_2$, we have:
\[
    \lim_{x \to x_0} P(x) = P(x_0) \quad \text{and} \quad \lim_{x \to x_0} R(x) = R(x_0)
\]

\begin{eg}
    Let's compute the limit:
    \[
        \lim_{x \to 1} \frac{2x^5 - 3x^3 + 2x + 1}{x^4 + 2x^2 - 6x}
    \]
    We have:
    \[
        \lim_{x \to 1} (2x^5 - 3x^3 + 2x + 1) = 2(1)^5 - 3(1)^3 + 2(1) + 1 = 2 - 3 + 2 + 1 = 2
    \]
    and:
    \[
        \lim_{x \to 1} (x^4 + 2x^2 - 6x) = (1)^4 + 2(1)^2 - 6(1) = 1 + 2 - 6 = -3
    \]
    Therefore, we can apply the quotient rule:
    \[
        \lim_{x \to 1} \frac{2x^5 - 3x^3 + 2x + 1}{x^4 + 2x^2 - 6x} = \frac{2}{-3} = -\frac{2}{3}
    \]
\end{eg}

\begin{theorem}[Sandwich Theorem for Functions]
    Let $f, g, h: E \to F$ be three functions defined on a neighborhood of a point $x_0 \in E$. If there exists $\alpha > 0$ such that for all $x \in \left\{x\in E: 0 < |x-x_0| \leq \alpha\right\}$, we have:
    \[
        f(x) \leq g(x) \leq h(x)
    \]
    and if:
    \[
        \lim_{x \to x_0} f(x) = \lim_{x \to x_0} h(x) = L
    \]
    then:
    \[
        \lim_{x \to x_0} g(x) = L
    \]
\end{theorem}
\begin{proof}
    Let $(a_n) \in \left\{x \in E - \left\{x_0\right\}\right\}$ be a sequence such that $\lim_{n \to +\infty} a_n = x_0$. There exists $m \in \mathbb{N}: \forall n \geq m$ we have:
    \[
        0 < |a_n - x_0| < \alpha
    \]
    Thus, for all $n \geq m$, we have:
    \[
        f(a_n) \leq g(a_n) \leq h(a_n)
    \]
    Since $\lim_{x \to x_0} f(x) = L$ and $\lim_{x \to x_0} h(x) = L$, by the caracterization of limits by sequences, we have:
    \[
        \lim_{n \to +\infty} f(a_n) = L \quad \text{and} \quad \lim_{n \to +\infty} h(a_n) = L
    \]
    Therefore, by the Sandwich Theorem for Sequences, we conclude that:
    \[
        \lim_{n \to +\infty} g(a_n) = L
    \]
    Since the sequence $(a_n)$ was arbitrary, by the caracterization of limits by sequences, we conclude that:
    \[
        \lim_{x \to x_0} g(x) = L
    \]
\end{proof}

\begin{eg}
    Let $g: \mathbb{R} \to \mathbb{R}$ a function such that $\lim_{x \to 0} g(x) = 0$, then:
    \[
        \lim_{x \to 0} \sqrt{1 + g(x)} = 1
    \]
    To show this, we can use the Sandwich Theorem. We know that:
    \[
        1 - |t| \leq \sqrt{1 + t} \leq \left|1 + \frac{1}{2}t\right|, \forall t \geq -1
    \]
    Since:
    \[
        \sqrt{1 + t} \leq \sqrt{1 + t + \frac{t^2}{4}} = \sqrt{\left(1 + \frac{t}{2}\right)^2} = \left|1 + \frac{1}{2}t\right|, \forall t \in \mathbb{R}
    \]
    and:
    \[
        t \geq 0 \implies 1 - |t| = 1 - t \leq 1 \leq \sqrt{1 + t} \quad \text{and} \quad -1 < t < 0 \implies 1 - |t| = 1 + t \leq \sqrt{1 + t}
    \]
    Thus, since $\lim_{x \to 0} g(x) = 0$, there exists $\delta > 0$ such that if $|x| < \delta$, we have:
    \[
        |g(x)| \leq 1 \quad \text{and} \quad g(x) \geq -1
    \]
    Therefore, we have:
    \[
        \underbrace{1 - |g(x)|}_{\to 1 \ (x \to 0)} \leq \sqrt{1 + g(x)} \leq \underbrace{\left|1 + \frac{1}{2}g(x)\right|}_{\to 1 \ (x \to 0)}
    \]
    By the Sandwich Theorem, we conclude that:
    \[
        \lim_{x \to 0} \sqrt{1 + g(x)} = 1
    \]
\end{eg}

\begin{eg}
    Let $f(x) = x^2 \cdot \cos\left(\frac{1}{x}\right)$ be a function not defined in $x = 0$. We want to compute:
    \[
        \lim_{x \to 0} f(x)
    \]
    We have:
    \[
        -1 \leq \cos\left(\frac{1}{x}\right) \leq 1 \quad \underbrace{\implies}_{x^2 \geq 0} \quad -x^2 \leq x^2 \cdot \cos\left(\frac{1}{x}\right) \leq x^2
    \]
    Since:
    \[
        \lim_{x \to 0} -x^2 = 0 \quad \text{and} \quad \lim_{x \to 0} x^2 = 0
    \]
    By the Sandwich Theorem, we conclude that:
    \[
        \lim_{x \to 0} x^2 \cdot \cos\left(\frac{1}{x}\right) = 0
    \]
\end{eg}
From the example above, we can also visualize the functions:
\begin{figure}[h]
    \centering
    \begin{minipage}{0.45\textwidth}
        \begin{center}
            \begin{tikzpicture}[scale=1.5]
                \draw[->] (-1.75, 0) -- (1.75, 0) node[right] {$x$};
                \draw[->] (0, -1.25) -- (0, 1.25) node[above] {$y$};
                \draw[thick, primary, domain=-1.5:1.5, samples=300] plot (\x, {cos(deg(1 / \x))});
            \end{tikzpicture}
        \end{center}
        \caption*{Graph of $\cos\left(\frac{1}{x}\right)$}
    \end{minipage}
    \hfill
    \begin{minipage}{0.45\textwidth}
        \begin{center}
            \begin{tikzpicture}[scale=2.35]
                \draw[->] (-1.2, 0) -- (1.2, 0) node[right] {$x$};
                \draw[->] (0, -0.3) -- (0, 1.25) node[above] {$y$};
                \draw[thick, primary, domain=-1.05:1.05, samples=200] plot (\x, {cos(deg(1 / \x)) * (\x * \x)});
            \end{tikzpicture}
        \end{center}
        \caption*{Graph of $x^2 \cdot \cos\left(\frac{1}{x}\right)$}
    \end{minipage}
\end{figure}

\begin{eg}
    Let's compute the limit:
    \[
        \lim_{x \to 0} \frac{\sin x}{x}
    \]
    For $x$ close to $0$ ($x \neq 0$ thus $\sin x \neq 0$), we can bound $\sin x$ by:
    \[
        |\sin x| \leq |x| \leq |\tan x|
    \]
    Since $\sin x \neq 0$, we can divide the inequalities by $|\sin x|$:
    \[
        1 \leq \left|\frac{x}{\sin x}\right| \leq \left|\frac{1}{\cos x}\right| \quad \iff \quad 1 \leq \frac{x}{\sin x} \leq \frac{1}{\cos x}
    \]
    We have:
    \[
        \cos 2\alpha = (\cos \alpha)^2 - (\sin \alpha)^2 = 1 - 2(\sin \alpha)^2 \quad \implies \quad 1 - \cos 2\alpha = 2 (\sin \alpha)^2
    \]
    and:
    \[
        |1 - \cos x| = 2 \left|\left(\sin \frac{x}{2}\right)^2\right| = \left(\sin \frac{x}{2}\right)^2 \leq 2 \left|\frac{x}{2}\right|^2 = \frac{x^2}{2} \quad \implies \quad |\cos x - 1| \leq \frac{x^2}{2}
    \]
    By the Squeeze Theorem, we have:
    \[
        0 \leq |1 - \cos x| \leq \frac{x^2}{2} \quad \implies \quad \lim_{x \to 0} |1 - \cos x| = 0 \quad \implies \quad \lim_{x \to 0} \cos x = 1
    \]
    and:
    \[
        \lim_{x \to 0} \frac{1}{\cos x} = 1
    \]
    Finally, by the Squeeze Theorem, we conclude that:
    \[
        1 \leq \frac{x}{\sin x} \leq \underbrace{\frac{1}{\cos x}}_{= 1} \quad \implies \quad \lim_{x \to 0} \frac{x}{\sin x} = 1 \quad \implies \quad \lim_{x \to 0} \frac{\sin x}{x} = 1
    \]
\end{eg}

\subsection{Limits of Composite Functions}
\begin{theorem}[Limits of Composite Functions]
    Let $f: E \to F$ and $g: F \to G$ be two functions such that $\lim_{x \to x_0} f(x) = y_0$ and $\lim_{y \to y_0} g(y) = L$. If there exists $\alpha > 0$ such that for all $x \in \left\{y \in E: 0 < |y - x_0| < \alpha\right\}$, we have $f(x) \neq y_0$, then:
    \[
        \lim_{x \to x_0} g(f(x)) = L
    \]
\end{theorem}
Remark that the condition $f(x) \neq y_0$ is necessary because $g(y_0)$ might not be defined and thus we cannot have $f(x)$ approaching $y_0$ directly.
\begin{proof}
    Let $\lim_{y \to y_0} g(y) = L$, we have for a given $\epsilon > 0$, there exists $\delta_1 > 0$ such that for all $y \in F$ with $0 < |y - y_0| < \delta_1$, we have:
    \[
        |g(y) - L| < \epsilon
    \]
    Since $\lim_{x \to x_0} f(x) = y_0$, there exists $\delta_2 > 0$ such that for all $x \in E$ with $0 < |x - x_0| < \delta_2$, we have:
    \[
        |f(x) - y_0| < \delta_1
    \]
    Let $\delta = \min(\alpha, \delta_2)$, then for all $x \in E$ with $0 < |x - x_0| < \delta$, we have:
    \[
        |f(x) - y_0| < \delta_1
    \]
    and since $f(x) \neq y_0$, we can apply the first inequality:
    \[
        |g(f(x)) - L| < \epsilon
    \]
    Therefore, we conclude that:
    \[
        \lim_{x \to x_0} g(f(x)) = L
    \]
\end{proof}
This theorem allows to change the variable in a limit computation.

\begin{eg}
    Let's compute the limit:
    \[
        \lim_{x \to 0} \frac{\cos(4x) - \cos(2x)}{x^2}
    \]
    If we compute the limit directly, we get the indeterminate form $\frac{0}{0}$. To resolve this, we can use the trigonometric identity ($\cos (2\alpha) = 1 - 2 (\sin \alpha)^2$), we get:
    \[
        \lim_{x \to 0} \frac{1 - (\sin(2x))^2 - 1 + 2(\sin x)^2}{x^2} = \lim_{x \to 0} 2 \cdot \frac{(\sin x)^2 - (\sin(2x))^2}{x^2}
    \]
    Thus, we can rewrite the limit as:
    \[
        \lim_{x \to 0} 2\left(\underbrace{\left(\frac{\sin x}{x}\right)^2}_{\to 1^2} - \underbrace{\left(\frac{\sin(2x)}{2x}\right)^2}_{\to 1^2} \cdot 4\right) = 2(1-4) = -6
    \]
\end{eg}

\begin{eg}
    Let's compute the limit:
    \[
        \lim_{x \to 2} \frac{\sqrt{x + 2} - \sqrt{2x}}{\sqrt{x -1} -1}
    \]
    Again, if we compute the limit directly, we get the indeterminate form $\frac{0}{0}$. To resolve this, we can multiply the numerator and denominator by the conjugate of each:
    \[
        \lim_{x \to 2} \frac{(\sqrt{x + 2} - \sqrt{2x})(\sqrt{x + 2} + \sqrt{2x})}{(\sqrt{x -1} -1)(\sqrt{x -1} +1)} = \lim_{x \to 2} \frac{(x + 2) - 2x}{(x -1) - 1} \cdot \frac{\sqrt{x -1} +1}{\sqrt{x + 2} + \sqrt{2x}}
    \]
    Thus, we can rewrite the limit as:
    \[
        \lim_{x \to 2} \frac{2 - x}{x - 2} \cdot \lim_{x \to 2} \frac{\sqrt{x -1} +1}{\sqrt{x + 2} + \sqrt{2x}} = -1 \cdot \frac{\sqrt{2 -1} +1}{\sqrt{2 + 2} + \sqrt{4}} = -\frac{1 + 1}{2 + 2} = -\frac{1}{2}
    \]
\end{eg}
Remark that by the theorem above, $\lim_{x \to 0} \frac{\sin (t(x))}{t(x)} = 1$ if $\lim_{x \to 0} t(x) = 0$ and $t(x) \neq 0$ for $x \neq 0$ close to $0$.

\begin{eg}
    Let's compute the limit:
    \[
        \lim_{x \to 3} \frac{\sin(\sqrt{x + 1} - 2)}{x -3}
    \]
    Since $\lim_{x \to 3} \sqrt{x + 1} - 2 = 0$, we can rewrite the limit as:
    \[
        \lim_{x \to 3} \underbrace{\frac{\sin(\sqrt{x + 1} -2)}{\sqrt{x + 1} -2}}_{\to 1} \cdot \frac{\sqrt{x + 1} -2}{x -3} = \lim_{x \to 3} \frac{\sin(\sqrt{x + 1} -2)}{\sqrt{x + 1} -2} \cdot \frac{x + 1 - 4}{\sqrt{x + 1} + 2} \cdot \frac{1}{x-3}
    \]
    Thus, we can rewrite the limit as:
    \[
        \lim_{x \to 3} \frac{\sin(\sqrt{x + 1} -2)}{\sqrt{x + 1} -2} \cdot \frac{x -3}{x -3 } \cdot \frac{1}{\sqrt{x + 1} + 2} = 1 \cdot 1 \cdot \frac{1}{\sqrt{4} + 2} = \frac{1}{4}
    \]
\end{eg}
Remark that the $\sin$ simplification would not be valid, for example, if $t(x) = x^2 \cos(\frac{1}{x})$ because the function $t(x)$ is not defined in the neighborhood of $0$.

\begin{eg}
    Let's prove that the limit $\lim_{x \to 0} \sin(\frac{1}{x})$ does not exists. To show this, we can consider two sequences $(a_n)$ and $(b_n)$ defined by:
    \[
        a_n = \frac{1}{\pi n} \quad \text{and} \quad b_n = \frac{1}{\frac{\pi}{2} + 2\pi n}
    \]
    for all $n \in \mathbb{N}^*$. We have:
    \[
        \lim_{n \to +\infty} a_n = \lim_{n \to +\infty} b_n = 0
    \]
    However, we have:
    \[
        \lim_{n \to +\infty} \sin\left(\frac{1}{a_n}\right) = \lim_{n \to +\infty} \sin(\pi n) = 0
    \]
    and:
    \[
        \lim_{n \to +\infty} \sin\left(\frac{1}{b_n}\right) = \lim_{n \to +\infty} \sin\left(\frac{\pi}{2} + 2\pi n\right) = 1
    \]
    Since the two sequences $(\sin(\frac{1}{a_n}))$ and $(\sin(\frac{1}{b_n}))$ converge to different limits, by the caracterization of limits by sequences, we conclude that the limit $\lim_{x \to 0} \sin(\frac{1}{x})$ does not exists.
\end{eg}
In general, to prove that a limit does not exits, two sequences converging to the same point can be used to show that the function values converge to different limits.

\begin{eg}
    Let's compute the limit:
    \[
        \lim_{x \to 0} x \cdot \sin\left(\frac{1}{x}\right) \quad \text{where} \quad D(f) = \mathbb{R} - \left\{0\right\}
    \]
    By using the Squeeze Theorem, we have:
    \[
        -1 \leq \sin \frac{1}{x} \leq 1 \quad \iff \quad 0 \leq \left|\sin \frac{1}{x}\right| \leq 1
    \]
    Multplying by $|x|$ (which is positive when $x \to 0$), we get:
    \[
        0 \leq \left|x \cdot \sin\frac{1}{x}\right| \leq \underbrace{|x|}_{\to 0}
    \]
    Thus, by the Squeeze Theorem, we conclude that:
    \[
        \lim_{x \to 0} x \cdot \sin\left(\frac{1}{x}\right) = 0
    \]
\end{eg}

\subsection{Limits at Infinity and Infinite Limits}
\begin{definition}[Neighborhoods of Infinity]
    Let $f: E \to F$ is defined on a neighborhood of $+\infty$ (resp. $-\infty$) if there exists $\alpha \in \mathbb{R}: (\alpha, +\infty) \subset E$ (resp. $(-\infty, \alpha) \subset E$).
\end{definition}

\begin{definition}[Limit at Infinity] 
    Let $f: E \to F$ be a function defined on a neighborhood of $+\infty$ (resp. $-\infty$). It is said that the limit of $f(x)$ as $x$ approaches $+\infty$ (resp. $-\infty$) is equal to $L \in F$ if for every $\epsilon > 0$, there exists $M > 0$ such that for all $x \in E$ with $x > M$ (resp. $x < -M$), we have:
    \[
        |f(x) - L| < \epsilon
    \]
    This is denoted by:
    \[
        \lim_{x \to +\infty} f(x) = L \quad \left(\text{resp. } \lim_{x \to -\infty} f(x) = L\right)
    \]
    In this case, it is said that the function $f$ has a horizontal asymptote $y = L$ at $+\infty$ (resp. $-\infty$).
\end{definition}
% TODO: add graph

\begin{eg}
    Let's prove that the limit:
    \[
        \lim_{x \to \infty} \frac{1}{x^2} = 0
    \]
    To show this, let $\epsilon > 0$ be given. We need to find $M > 0$ such that for all $x > M$, we have:
    \[
        \left|\frac{1}{x^2} - 0\right| < \epsilon
    \]
    We have:
    \[
        \left|\frac{1}{x^2} - 0\right| = \frac{1}{x^2} < \epsilon \quad \iff \quad x^2 > \frac{1}{\epsilon} \quad \iff \quad x > \frac{1}{\sqrt{\epsilon}}
    \]
    Thus, we can choose $M = \frac{1}{\sqrt{\epsilon}}$. Therefore, for all $x > M$, we have:
    \[
        \left|\frac{1}{x^2} - 0\right| < \epsilon
    \]
    Thus, we conclude that:
    \[
        \lim_{x \to \infty} \frac{1}{x^2} = 0
    \]
\end{eg}

\begin{definition}[Infinite Limits]
    Let $f: E \to F$ be a function defined on a neighborhood of $x_0 \in E$. It is said that the limit of $f(x)$ as $x$ approaches $x_0$ is equal to $+\infty$ (resp. $-\infty$) if for every $M > 0$, there exists $\delta > 0$ such that for all $x \in E$ with $0 < |x - x_0| < \delta$, we have:
    \[
        f(x) > M \quad (\text{resp. } f(x) < -M)
    \]
    This is denoted by:
    \[
        \lim_{x \to x_0} f(x) = +\infty \quad (\text{resp. } \lim_{x \to x_0} f(x) = -\infty)
    \]
    In this case, it is said that the function $f$ has a vertical asymptote $x = x_0$.
\end{definition}

\begin{eg}
    Let's prove the following limit:
    \[
        \lim_{x \to 0} \frac{1}{x^2} = +\infty
    \]
    To show this, let $M > 0$ be given. We need to find $\delta > 0$ such that for all $x \in E$ with $0 < |x - 0| < \delta$, we have:
    \[
        \frac{1}{x^2} > M
    \]
    We have:
    \[
        \frac{1}{x^2} > M \quad \iff \quad |x| < \frac{1}{\sqrt{M}}
    \]
    Thus, we can choose $\delta = \frac{1}{\sqrt{M}}$. Therefore, for all $x \in E$ with $0 < |x| < \delta$, we have:
    \[
        \frac{1}{x^2} > M
    \]
    Thus, we conclude that:
    \[
        \lim_{x \to 0} \frac{1}{x^2} = +\infty
    \]
\end{eg}

\begin{eg}
    Let's show that the following limit does not exist:
    \[
        \lim_{x \to 0} \frac{1}{x}
    \]
    To show this, we can consider two sequences $(a_n)$ and $(b_n)$ defined by:
    \[
        a_n = \frac{1}{n} \quad \text{and} \quad b_n = -\frac{1}{n}
    \]
    for all $n \in \mathbb{N}^*$. We have:
    \[
        \lim_{n \to +\infty} a_n = \lim_{n \to +\infty} b_n = 0
    \]
    However, we have:
    \[
        \lim_{n \to +\infty} \frac{1}{a_n} = \lim_{n \to +\infty} n = +\infty
    \]
    and:
    \[
        \lim_{n \to +\infty} \frac{1}{b_n} = \lim_{n \to +\infty} -n = -\infty
    \]
    Since the two sequences $(\frac{1}{a_n})$ and $(\frac{1}{b_n})$ converge to different limits, by the caracterization of limits by sequences, we conclude that the limit $\lim_{x \to 0} \frac{1}{x}$ does not exist.
\end{eg}

\begin{definition}[Infite Limits at Infinity]
    Let $f: E \to F$ be a function defined on a neighborhood of $+\infty$ (resp. $-\infty$). It is said that the limit of $f(x)$ as $x$ approaches $+\infty$ (resp. $-\infty$) is equal to $+\infty$ (resp. $-\infty$) if for every $M > 0$, there exists $X > 0$ such that for all $x \in E$ with $x > X$ (resp. $x < -X$), we have:
    \[
        f(x) > M \quad (\text{resp. } f(x) < -M)
    \]
    This is denoted by:
    \[
        \lim_{x \to +\infty} f(x) = +\infty \quad (\text{resp. } \lim_{x \to -\infty} f(x) = -\infty)
    \]
\end{definition}
Note that all results shown for limits at finite points can be adapted to limits at infinity and vice versa.

\begin{eg}
    Some examples of infinite limits at infinity are:
    \[
        \lim_{x \to +\infty} x = +\infty, \quad \lim_{x \to -\infty} x = -\infty, \quad \lim_{x \to +\infty} e^x = +\infty, \quad \lim_{x \to -\infty} e^x = 0
    \]
\end{eg}

\subsection{Indeterminate Forms}
When computing limits, we can encounter some indeterminate forms such as:
\begin{itemize}[itemsep=1pt,label=$\circ$]
    \item $\frac{0}{0}$
    \item $\frac{\infty}{\infty}$
    \item $0 \cdot \infty$
    \item $\infty - \infty$
    \item $0^0$ (will be seen later)
    \item $1^\infty$ (will be seen later)
    \item $\infty^0$ (will be seen later)
\end{itemize}

\begin{eg}
    Let's compute the limit:
    \[
        \lim_{x \to \infty} (\sqrt{x^2 + 2x} - x)
    \]
    If we compute the limit directly, we get the indeterminate form $\infty - \infty$. To resolve this, we can multiply the expression by its conjugate:
    \[
        \lim_{x \to \infty} (\sqrt{x^2 + 2x} - x) \cdot \frac{\sqrt{x^2 + 2x} + x}{\sqrt{x^2 + 2x} + x} = \lim_{x \to \infty} \frac{(x^2 + 2x) - x^2}{\sqrt{x^2 + 2x} + x} = \lim_{x \to \infty} \frac{2x}{\sqrt{x^2 + 2x} + x}
    \]
    Thus, we can rewrite the limit as:
    \[
        \lim_{x \to \infty} \frac{2}{\sqrt{1 + \frac{2}{x}} + 1} = \frac{2}{\sqrt{1 + 0} + 1} = \frac{2}{2} = 1
    \]
\end{eg}

\begin{eg}
    Let's compute the limit:
    \[
        \lim_{x \to - \infty} (\sqrt{x^2 + 2x} + x)
    \]
    If we compute the limit directly, we get the indeterminate form $\infty - \infty$. To resolve this, we can multiply the expression by its conjugate:
    \[
        \lim_{x \to -\infty} (\sqrt{x^2 + 2x} + x) \cdot \frac{\sqrt{x^2 + 2x} - x}{\sqrt{x^2 + 2x} - x} = \lim_{x \to -\infty} \frac{(x^2 + 2x) - x^2}{\sqrt{x^2 + 2x} - x} = \lim_{x \to -\infty} \frac{2x}{\sqrt{x^2 + 2x} - x}
    \]
    Thus, we can rewrite the limit as:
    \[
        \lim_{x \to -\infty} \frac{2x}{\underbrace{\sqrt{x^2}}_{|x| = -x \ (x \to - \infty)} \sqrt{1 + \frac{1}{2}} - x} = = \lim_{x \to - \infty} \frac{2x}{-x \left(\sqrt{1 + \frac{2}{x}} + 1\right)} = -1
    \]
\end{eg}

\section{Exercices}
This section gathers a selection of exercises related to Chapter \thechapter, taken from weekly assignments, past exams, textbooks, and other sources. The origin of each exercise will be indicated at its beginning.

\begin{exercise}[Quizz of Lecture 13]
    Let $f(x) = 2 \sin(1 - x^2)$ on the biggest interval where it is bijective and containing $x= 1$. Then the set of the definition of $f^{-1}$ and its image is:
    \begin{itemize}[itemsep=1pt,label=$\circ$]
        \item $f^{-1}: \left[-2 \sin(1), 2 \sin(1)\right] \to \left[\sqrt{1 - \frac{\pi}{2}}, \sqrt{1 + \frac{\pi}{2}}\right]$
        \item $f^{-1}: \left[0, 2 \sin(1)\right] \to \left[0, \sqrt{1 + \pi}\right]$
        \item $f^{-1}: \left[-2, 2 \sin(1)\right] \to \left[0, \sqrt{1 + \frac{\pi}{2}}\right]$
        \item $f^{-1}: \left[-2, 2 \sin(1)\right] \to \left[-\sqrt{1 + \frac{\pi}{2}}, \sqrt{1 + \frac{\pi}{2}}\right]$
        \item $f^{-1}: \left[-2 \sin(1), 0\right] \to \left[0, \sqrt{1 + \pi}\right]$
    \end{itemize}
    \Answer
    The correct answer is the 3rd proposition because we have:
    \[
        f(x) = 2 \sin(1 - x^2) \quad \implies \quad - \frac{\pi}{2} + 2k\pi \leq 1 - x^2 \leq \frac{\pi}{2} + 2k\pi
    \]
    for $k = 0$ since $x = 1$ is in the interval. Thus:
    \[
        1 - \frac{\pi}{2} \leq x^2 \leq 1 + \frac{\pi}{2} \quad \iff \quad 0 \leq x^2 \leq 1 + \frac{\pi}{2}
    \]
    since $1 - \frac{\pi}{2} < 0$ and $x^2 \geq 0$. Therefore:
    \[
        0 \leq x \leq \sqrt{1 + \frac{\pi}{2}}
    \]
    Thus the domain of $f(x)$ is $\left[0, \sqrt{1 + \frac{\pi}{2}}\right] = E$ for it to be bijective and containing $x = 1$. Furthermore, we see that $f$ is decreasing on $E$ thus:
    \[
        \inf_{x \in E} f(x) = f\left(\sqrt{1 + \frac{\pi}{2}}\right) = -2 \quad \text{and} \quad \sup_{x \in E} f(x) = f(0) = 2 \sin(1)
    \]
    Therefore, the image of $f$ is $\left[-2, 2 \sin(1)\right]$.
\end{exercise}

\begin{exercise}[Quizz of Lecture 14]
    Let's compute the limit:
    \[
        \lim_{x \to 0} \frac{\sqrt{1 + x^2}}{\sqrt{1 + \left(\sin\frac{1}{x}\right)^2} + \sqrt{1 - \left(\sin\frac{1}{x}\right)^2}}
    \]
    \Answer
    Since $x^2 \geq 0$, we have:
    \[
        1 \leq \sqrt{1 + x^2} \leq \underbrace{1 + \frac{1}{2}x^2}_{\to 1 \ (x \to 0)}
    \]
    Thus by the Sandwich Theorem, we conclude that $\lim_{x \to 0} \sqrt{1 + x^2} = 1$. Let's take two sequences $(a_k) = \frac{1}{\pi k}$ and $(b_k) = \frac{1}{\frac{\pi}{2} + 2\pi k}$ such that $\lim_{k \to \infty} a_k = b_k = 0$. We have:
    \[
        \lim_{k \to \infty} \left(\sqrt{1 + \left(\sin \frac{1}{a_k}\right)^2} + \sqrt{1 - \left(\sin \frac{1}{a_k}\right)^2}\right) = \lim_{k \to \infty} \left(\sqrt{1 + \underbrace{(\sin a_k)^2}_{= 0}} + \sqrt{1 - \underbrace{(\sin a_k)^2}_{= 0}}\right)
    \]
    \[
        \lim_{k \to \infty} (1 + 1) = 2
    \]
    and:
    \[
        \lim_{k \to \infty} \left(\sqrt{1 + \left(\sin \frac{1}{b_k}\right)^2} + \sqrt{1 - \left(\sin \frac{1}{b_k}\right)^2}\right) = \lim_{k \to \infty} \left(\sqrt{1 + \underbrace{(\sin b_k)^2}_{= 1}} + \sqrt{1 - \underbrace{(\sin b_k)^2}_{= 1}}\right)
    \]
    \[
        \lim_{k \to \infty} (\sqrt{2} + 0) = \sqrt{2}
    \]
    Thus:
    \[
        \lim_{k \to \infty} f(a_k) = \frac{1}{2} \quad \text{and} \quad \lim_{k \to \infty} f(b_k) = \frac{1}{\sqrt{2}}
    \]
    Since the two limits are different, we conclude that the limit $\lim_{x \to 0} f(x)$ does not exist.
\end{exercise}